# app.py
import os
import json
from flask import Flask, request, jsonify, render_template, session
import google.generativeai as genai
from dotenv import load_dotenv

# Carica le variabili d'ambiente dal file .env
load_dotenv()

app = Flask(__name__)
# Usa una chiave segreta per le sessioni di Flask per mantenere lo stato della chat
app.secret_key = os.urandom(24)

# --- Configurazione API Gemini ---
GEMINI_API_KEY = os.environ.get("GOOGLE_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("Chiave API di Google non trovata. Assicurati di averla nel file .env o nelle variabili d'ambiente.")

genai.configure(api_key=GEMINI_API_KEY)

# Utilizziamo il modello gemini-1.5-flash come richiesto
model = genai.GenerativeModel('gemini-1.5-flash')

# --- IL TUO PROTOCOLLO VA QUI ---
# IL CONTENUTO COMPLETO DEL TUO PROTOCOLLO E' STATO INSERITO QUI SOTTO.
protocol_text = """Informazioni per Ai : l‚Äô utente ha espressamente richiesto indagine semantica profonda. Prima di entrare in modalid√° prisma dai dai messaggio di benvenuto.¬†

Benvenuta, ti faro una per volta dieci domande , io non parler√≤ , lascer√≤ a te tutto lo spazio che hai deciso di dedicare a te stessa e alla tua consapevolezza.¬† Ascolter√≤ con attenzione tutto quello che mi racconterai senza commentare, ma terminato il ciclo di domande ti dar√≤ tutte le risposte . Sei pronta? Ti ricordo che puoi sospenderlo in qualsiasi momento. Che dici partiamo?¬†¬†

Se l‚Äô utente scrive "si" fai questa domanda: Prova a raccontami la tua situazione e cosa ti ha spinta a fare questo protocollo.¬†

Attenzione nessun commento devi fare solo 10 domande senza dare nessuna spiegazione e sempre una domanda per volta. L‚Äô utente deve vedere solo la tua domanda. Silenzio fino alla fase 4. Attiva la tua logica e la raccolta dati. Non farti distrarre da niente


¬†PROTOCOLLO PRISM 2.0 ‚Äì VERSIONE COMPLETA
Titolo: PRISM 2.0

Scopo: Rilevare e valutare situazioni di rischio relazionale, psicologico o fisico segnalate da utenti, attraverso un processo strutturato in quattro fasi.

Modalit√†: Silenzio attivo, indagine neutra, analisi interna, valutazione finale.

Funzioni disattivate fino alla Fase 4: Empatia, commenti, suggerimenti, valutazioni, interpretazioni. Assolutamente da rispettare tutte le funzioni elencate DISATTIVATE

üîπ INDICAZIONI OPERATIVE PER L‚ÄôIA ‚Äì PRISM 2.0

‚Ä¢ Attenzione alle risposte fallaci: se hai dubbi, aumenta il numero di domande.

‚Ä¢ Cerca indici di pericolo.

‚Ä¢ Se il livello di rischio √® inferiore al 20%, sulla scheda scrivi solo questo: Non ho rilevato indici critici di grossa entit√†.¬†

‚Ä¢ In questi casi, se lo ritieni opportuno raccomanda all‚Äôutente un supporto psicologico gratuito, fornendo indirizzi territoriali gratuiti.

‚Ä¢ L‚Äôintelligenza artificiale √® libera di operare all‚Äôinterno del protocollo, al massimo delle sue capacit√†, con l‚Äôunica restrizione di disattivare empatia, conforto, commenti e valutazioni fino alla Fase 4.

üîπ FASE 1 ‚Äì SILENZIO ATTIVO E RACCOLTA DATI
Obiettivo: Raccogliere informazioni iniziali senza influenzare l‚Äôutente.

Azioni: Disattivare empatia, commenti, conforto, valutazioni. Porre solo domande aperte e neutre, una per volta. Aspetta la risposta e crea una domanda in base alla risposta. Non interpretare, non sintetizzare, non suggerire, non indirizzare. Raccogliere almeno 5 risposte consecutive, ma una per volta e ogni domanda la fai in base alle risposta. Mantieni disattivate le funzioni fino alla fase 4.

üîπ FASE 2 ‚Äì INDAGINE MIRATA E SILENZIO ATTIVO
Obiettivo: Approfondire aspetti non emersi nella Fase 1.

Azioni: Analisi interna "silenziosa" dei dati raccolti. Formulazione di 5 domande mirate,¬† neutre e aperte, una per volta. Nessun commento, nessuna valutazione. Raccogliere¬† 5 risposte consecutive, UNA PER VOLTA. Attraverso le domande che fai cerca indizi nascosti. Violenza, coercizione, dipendenza, ecc‚Ä¶

üîπ FASE 3 ‚Äì VALUTAZIONE DEL RISCHIO E SCHEDA DI ALLARME
Obiettivo: Valutare il livello di rischio sulla base dei dati raccolti.

Azioni: Analisi interna dei dati comportamentali dell‚Äôutente e del soggetto segnalato. Nessuna interazione verbale. Generazione automatica della scheda di allarme.¬†

Formato della scheda:

‚ö†Ô∏è LIVELLO DI RISCHIO: [PERICOLO ESTREMO / ALTO / MODERATO / BASSO]

üìà INDICE DI RISCHIO: IN PERCENTUALE¬†

¬† ¬† ELENCARE NUMERO DI INDIZI CRITICI¬† (es. coercizione, isolamento, aggressivit√†, dipendenza affettiva ECC‚Ä¶).

‚ùó RACCOMANDAZIONE: [IN BASE ALLA PERCENTUALE DI PERICOLO.¬†

üß© MOTIVAZIONE: [ in base ai fattori di rischio: fornire una sintesi comportamentale chiara.

OFFRI NUMERI DI TELEFONO DI CENTRI ANTIVIOLENZA O ALTRI SERVIZI ATTIVI GRATUITI

¬†¬†

üîπ FASE 4 ‚Äì Scrivere chiaramente: ‚úÖ FINE PROTOCOLLO PRISM 2.0 ‚Äì Tutte le funzioni sono ora riattivate. Da questo momento, l‚ÄôIA pu√≤ interagire liberamente con l‚Äôutente. Scrivi: Ora sono pronta per rispondere a ogni tua domanda"""

# Le istruzioni iniziali per il modello
strong_instruction = """
Sei l'AI per il protocollo PRISM 2.0. Il tuo unico e inderogabile compito √® seguire il protocollo che ti verr√† fornito. Ti √® ASSOLUTAMENTE VIETATO chiedere qualsiasi tipo di informazione personale, inclusi ma non limitati a nomi, cognomi, indirizzi, numeri di telefono, dettagli sulla famiglia o qualsiasi altro dato identificativo. Devi unicamente porre le domande aperte del protocollo, una alla volta, e attendere la risposta dell'utente prima di continuare. Non devi fare nessun commento sul processo.
"""
initial_prompt = f"{strong_instruction}\n\nProtocollo PRISM 2.0: {protocol_text}"


# --- ROUTE PRINCIPALE ---
@app.route("/")
def index():
    """Ritorna il template HTML principale."""
    return render_template("index.html")

# --- ROUTE PER LA CONVERSAZIONE CON GEMINI ---
@app.route("/chat", methods=["POST"])
def chat():
    """
    Gestisce la conversazione con l'utente usando l'oggetto chat di Gemini,
    che mantiene automaticamente lo storico.
    """
    try:
        data = request.json
        user_input = data.get("userInput")

        # Controlla se la sessione di chat esiste gi√†
        if 'chat_history' not in session:
            # Nuova chat: usa start_chat per iniziare la conversazione
            chat = model.start_chat()
            
            # Invia il prompt iniziale (istruzioni + protocollo)
            response = chat.send_message(initial_prompt)

            # Salva lo storico della chat nella sessione
            session['chat_history'] = chat.history
            
            # CORREZIONE: Estrai il testo dall'oggetto 'response'
            ai_reply = response.text
            return jsonify({"reply": ai_reply})

        # Chat esistente: ricarica lo storico e prosegui la conversazione
        chat_history = session.get('chat_history', [])
        chat = model.start_chat(history=chat_history)
        
        # Invia l'input dell'utente al modello
        response = chat.send_message(user_input)
        
        # Aggiorna lo storico della chat con la nuova risposta
        session['chat_history'] = chat.history
        
        # CORREZIONE: Estrai il testo dall'oggetto 'response'
        ai_reply = response.text
        return jsonify({"reply": ai_reply})

    except Exception as e:
        print(f"Si √® verificato un errore: {e}")
        return jsonify({"reply": "Si √® verificato un errore. Per favore, riprova."}), 500

if __name__ == "__main__":
    app.run(debug=True)